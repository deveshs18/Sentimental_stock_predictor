# Sentimental Stock Predictor

## Overview

This project is a Python-based pipeline that analyzes financial news and Reddit discussions to predict potential stock growth. It uses sentiment analysis, keyword weighting, time decay factors, and overall market sentiment to calculate growth scores for various companies. Finally, it leverages an OpenAI GPT model to interpret these scores and provide a qualitative prediction for the top 3 companies likely to show growth.

## Project Architecture

The project consists of a series of Python scripts orchestrated by `scripts/run_all.py`. The typical workflow is as follows:

1.  **Data Collection:**
    *   News articles are fetched from NewsAPI.
    *   Reddit posts are fetched (presumably related to finance/stocks).
2.  **Data Processing:**
    *   Collected data is merged.
    *   Entities (like company names) are extracted.
    *   Company names are normalized for consistency.
3.  **Sentiment Analysis:**
    *   Sentiment (positive, negative, neutral) is determined for the textual data, primarily using the FinBERT model (`yiyanghkust/finbert-tone`).
    *   Keyword analysis and weighting are performed.
    *   Company-specific and broader macro/market sentiment scores are generated.
4.  **Growth Prediction:**
    *   `scripts/predict_growth.py`: Calculates a quantitative `growth_score` for companies. This score incorporates:
        *   Sentiment of related news/discussions.
        *   Relevance of predefined financial keywords (from `data/edw_keywords.csv`).
        *   Time decay (recent news has more weight).
        *   Overall market sentiment (derived from VIX and S&P 500 data via `scripts/market_sentiment.py`).
    *   The results are saved in `data/predict_growth.csv`.
5.  **LLM-based Interpretation:**
    *   `scripts/stock_predictor.py`: Takes the top companies from `predict_growth.csv`, combines their scores with other sentiment data, and constructs a prompt for an OpenAI GPT model.
    *   The GPT model is asked to identify the top 3 companies likely to grow, estimate their percentage increase, and provide justifications.
    *   The final natural language prediction is saved in `output/gpt_prediction.txt`.

## Directory Structure

-   `data/`: Contains input CSVs (keywords, company lists), intermediate data files, and final outputs like `predict_growth.csv`.
-   `logs/`: Contains log files generated by the scripts (e.g., `predict_growth.log`).
-   `output/`: Contains the final prediction from the OpenAI model (`gpt_prediction.txt`).
-   `scripts/`: Contains all the Python scripts for the pipeline.
-   `utils/`: Contains utility Python modules.

## Key Scripts

-   `scripts/run_all.py`: Main orchestrator to run the entire pipeline.
-   `scripts/fetch_news.py`: Fetches news from NewsAPI.
-   `scripts/fetch_reddit.py`: Fetches data from Reddit.
-   `scripts/sentiment_analysis.py`: Performs sentiment analysis using FinBERT.
-   `scripts/predict_growth.py`: Calculates quantitative growth scores.
-   `scripts/stock_predictor.py`: Generates prompts and queries OpenAI for final predictions.
-   `scripts/market_sentiment.py`: Fetches market indicators (VIX, S&P 500) to assess overall market sentiment.

## Setup and Configuration

1.  **Clone the repository.**
2.  **Install dependencies:**
    ```bash
    pip install pandas requests python-dotenv torch transformers textblob nltk thefuzz openai
    ```
    *(Note: A `requirements.txt` file would be beneficial here.)*
3.  **NLTK Data:**
    The `predict_growth.py` script attempts to download necessary NLTK data (`punkt`, `averaged_perceptron_tagger`, `wordnet`). If this fails due to environment restrictions, you may need to download them manually in a Python interpreter:
    ```python
    import nltk
    nltk.download('punkt')
    nltk.download('averaged_perceptron_tagger')
    nltk.download('wordnet')
    ```
4.  **API Keys:**
    Create a `.env` file in the root directory of the project and add your API keys:
    ```env
    NEWS_API_KEY=your_newsapi_key_here
    OPENAI_API_KEY=your_openai_api_key_here
    ```
    Replace `your_newsapi_key_here` and `your_openai_api_key_here` with your actual API keys.

## How to Run

To run the entire pipeline, execute:

```bash
python scripts/run_all.py
```

The final prediction will be saved in `output/gpt_prediction.txt`. Individual scripts can also be run if their prerequisite data files exist.

## Areas for Improvement / Future Work

-   **Add `requirements.txt`:** For easier dependency management.
-   **Robust Error Handling:** Enhance error checking and resilience in all scripts.
-   **Configuration Management:** Centralize file paths and parameters.
-   **Backtesting:** Implement a framework to test the historical accuracy of `predict_growth.py` scores and potentially the LLM's suggestions.
-   **Expand Data Sources:** Incorporate more financial news sources, social media, or financial statements.
-   **Advanced Sentiment Models:** Explore fine-tuning sentiment models or using more domain-specific ones.
-   **Direct Prediction Model:** Consider developing a direct quantitative prediction model as an alternative or supplement to the LLM-based interpretation.
-   **Unit and Integration Tests:** Develop a test suite to ensure reliability.
-   **Code Refinement:** Address potential issues like the `TextBlob` fallback in `predict_growth.py` if FinBERT sentiment is intended.
-   **Detailed Logging:** Improve logging for better traceability and debugging.
